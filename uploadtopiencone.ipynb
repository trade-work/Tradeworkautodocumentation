{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in ./.venv/lib/python3.12/site-packages (0.3.3)\n",
      "Requirement already satisfied: langchain-pinecone in ./.venv/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (4.66.5)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.12/site-packages (8.1.5)\n",
      "Requirement already satisfied: tenacity in ./.venv/lib/python3.12/site-packages (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.12/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.12/site-packages (from langchain_community) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.12/site-packages (from langchain_community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.venv/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.4 in ./.venv/lib/python3.12/site-packages (from langchain_community) (0.3.4)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in ./.venv/lib/python3.12/site-packages (from langchain_community) (0.3.12)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in ./.venv/lib/python3.12/site-packages (from langchain_community) (0.1.136)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in ./.venv/lib/python3.12/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./.venv/lib/python3.12/site-packages (from langchain_community) (2.6.0)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.12/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: pinecone-client<6.0.0,>=5.0.0 in ./.venv/lib/python3.12/site-packages (from langchain-pinecone) (5.0.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (8.28.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.15.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (0.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.9)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in ./.venv/lib/python3.12/site-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (2024.8.30)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in ./.venv/lib/python3.12/site-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in ./.venv/lib/python3.12/site-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (0.0.7)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in ./.venv/lib/python3.12/site-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from yarl<2.0,>=1.0->aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.12/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install langchain_community langchain-pinecone tqdm python-dotenv ipywidgets tenacity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pinecone\n",
    "import openai\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone as LangchainPineconeVectorStore\n",
    "from langchain.docstore.document import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API keys and configurations\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "PINECONE_ENVIRONMENT = os.getenv('PINECONE_ENVIRONMENT')  # e.g., \"us-west1-gcp\"\n",
    "\n",
    "# Validate API keys\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OpenAI API key not found in environment variables.\")\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\"Pinecone API key not found in environment variables.\")\n",
    "if not PINECONE_ENVIRONMENT:\n",
    "    raise ValueError(\"Pinecone environment not found in environment variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='file_processing.log',\n",
    "    filemode='a',\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import time\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "if not os.getenv(\"PINECONE_API_KEY\"):\n",
    "    os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter your Pinecone API key: \")\n",
    "\n",
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = \"tradework-platform-code\"  # change if desired\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=3072,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"eu-west-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory exists: /Volumes/Mac-External/Development/Tradework/tradework_platform\n"
     ]
    }
   ],
   "source": [
    "# Set the path to your Flutter/Dart project directory\n",
    "repo_directory = \"/Volumes/Mac-External/Development/Tradework/tradework_platform\"\n",
    "\n",
    "# Verify that the directory exists\n",
    "if not os.path.exists(repo_directory):\n",
    "    raise FileNotFoundError(f\"Directory does not exist: {repo_directory}\")\n",
    "else:\n",
    "    print(f\"Directory exists: {repo_directory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata(file_path, comment_style='//'):\n",
    "    \"\"\"\n",
    "    Extracts metadata from the top of a Dart file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the Dart file.\n",
    "        comment_style (str): Comment prefix used in the metadata.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing metadata keys and their values.\n",
    "    \"\"\"\n",
    "    metadata = {}\n",
    "    required_keys = [\n",
    "        \"# File:\",\n",
    "        \"# Module:\",\n",
    "        \"# Description:\",\n",
    "        \"# Dependencies:\",\n",
    "        \"# Components:\",\n",
    "        \"# Role:\",\n",
    "        \"# Author:\",\n",
    "        \"# Date Created:\",\n",
    "        \"# Last Updated:\",\n",
    "        \"# Related Files:\",\n",
    "        \"# Key:\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                stripped_line = line.strip()\n",
    "                if stripped_line.startswith(comment_style):\n",
    "                    # Remove comment prefix and whitespace\n",
    "                    content = stripped_line.lstrip(comment_style).strip()\n",
    "                    for key in required_keys:\n",
    "                        if content.startswith(key):\n",
    "                            value = content[len(key):].strip()\n",
    "                            metadata[key.strip(\"#:\")] = value\n",
    "                            break\n",
    "                else:\n",
    "                    break  # Stop reading after the initial comments\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting metadata from {file_path}: {e}\")\n",
    "    \n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_content(file_path):\n",
    "    \"\"\"\n",
    "    Loads the content of a Dart file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the Dart file.\n",
    "\n",
    "    Returns:\n",
    "        str: Content of the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading file content from {file_path}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_folder_context(file_path):\n",
    "    \"\"\"\n",
    "    Determines the folder context based on the file path.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Absolute path to the file.\n",
    "\n",
    "    Returns:\n",
    "        str: Folder context description.\n",
    "    \"\"\"\n",
    "    if 'twcore' in file_path:\n",
    "        return \"Core Shared Components\"\n",
    "    elif 'shared_features' in file_path:\n",
    "        return \"Shared Features\"\n",
    "    elif 'users' in file_path:\n",
    "        return \"User-Specific Features\"\n",
    "    return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_imports(file_content):\n",
    "    \"\"\"Extracts import statements from a Dart file.\"\"\"\n",
    "    import_lines = []\n",
    "    for line in file_content.splitlines():\n",
    "        if line.strip().startswith('import'):\n",
    "            import_lines.append(line)\n",
    "    return import_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_import_path(import_statement, current_file_path, lib_directory):\n",
    "    \"\"\"\n",
    "    Extracts the file path from a Dart import statement.\n",
    "\n",
    "    Handles relative paths and package paths for local files.\n",
    "\n",
    "    Args:\n",
    "        import_statement (str): The import statement line.\n",
    "        current_file_path (str): Absolute path to the current file.\n",
    "        lib_directory (str): Absolute path to the lib directory.\n",
    "\n",
    "    Returns:\n",
    "        str or None: Absolute path to the imported file, or None if not found.\n",
    "    \"\"\"\n",
    "    # Match import statements like: import 'some_relative_path.dart';\n",
    "    match = re.search(r\"import\\s+['\\\"]([^'\\\"]+)['\\\"];\", import_statement)\n",
    "    \n",
    "    if match:\n",
    "        import_path = match.group(1)\n",
    "        \n",
    "        # Handle relative paths\n",
    "        if import_path.startswith('.'):\n",
    "            # Convert relative paths to absolute paths based on the current file's location\n",
    "            base_dir = os.path.dirname(current_file_path)\n",
    "            absolute_path = os.path.abspath(os.path.join(base_dir, import_path))\n",
    "            # Ensure the path points to a Dart file\n",
    "            if not absolute_path.endswith('.dart'):\n",
    "                absolute_path += '.dart'\n",
    "            if os.path.exists(absolute_path):\n",
    "                return absolute_path\n",
    "        \n",
    "        # Handle package paths\n",
    "        elif import_path.startswith('package:tradework_platform/'):\n",
    "            # Remove 'package:tradework_platform/' and map to lib_directory\n",
    "            relative_path = import_path.replace('package:tradework_platform/', '')\n",
    "            absolute_path = os.path.join(lib_directory, relative_path)\n",
    "            if os.path.exists(absolute_path):\n",
    "                return absolute_path\n",
    "        \n",
    "        # Handle other package paths if needed\n",
    "        elif import_path.startswith('package:'):\n",
    "            # You can add custom logic to map other package imports to actual file paths in your repo if needed\n",
    "            return None\n",
    "        \n",
    "    return None  # If not a valid import line or if a package import (ignored for now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_metadata(file_path, comment_style, required_keys=None):\n",
    "    \"\"\"\n",
    "    Checks if the file already contains the metadata block.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Absolute path to the file.\n",
    "        comment_style (str): The comment prefix based on file type (e.g., '//', '#').\n",
    "        required_keys (list, optional): List of required metadata keys. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if all required metadata keys are found, False otherwise.\n",
    "    \"\"\"\n",
    "    if required_keys is None:\n",
    "        required_keys = [\n",
    "            \"File:\",\n",
    "            \"Module:\",\n",
    "            \"Description:\",\n",
    "            \"Dependencies:\",\n",
    "            \"Components:\",\n",
    "            \"Role:\",\n",
    "            \"Author:\",\n",
    "            \"Date Created:\",\n",
    "            \"Last Updated:\",\n",
    "            \"Related Files:\",\n",
    "            \"Key:\"\n",
    "        ]\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            # Read the first N lines where N is the number of required keys\n",
    "            for _ in range(len(required_keys)):\n",
    "                line = file.readline()\n",
    "                if not line:\n",
    "                    break  # Reached EOF\n",
    "                # Remove comment prefix and leading/trailing whitespace\n",
    "                stripped_line = line.strip().lstrip(comment_style).strip()\n",
    "                # Check for each required key\n",
    "                for key in required_keys:\n",
    "                    if stripped_line.startswith(key):\n",
    "                        return True\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error checking metadata in file {file_path}: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect All Relevant Dart Files\n",
    "Gather all Dart files in the lib directory, excluding auto-generated files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Dart files found: 1041\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define the lib directory\n",
    "lib_directory = Path(repo_directory) / \"lib\"\n",
    "\n",
    "# Collect all Dart files excluding those ending with .freezed.dart or .g.dart\n",
    "dart_files = list(lib_directory.rglob(\"*.dart\"))\n",
    "filtered_dart_files = [f for f in dart_files if not f.name.endswith(('.freezed.dart', '.g.dart'))]\n",
    "\n",
    "print(f\"Total Dart files found: {len(filtered_dart_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Metadata from All Files\n",
    "Create a list of dictionaries containing file paths and their associated metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8569ae9f064ddc9dbccbb9b79286d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting metadata:   0%|          | 0/1041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_metadata_list = []\n",
    "\n",
    "for file_path in tqdm(filtered_dart_files, desc=\"Extracting metadata\"):\n",
    "    metadata = extract_metadata(file_path)\n",
    "    if metadata:\n",
    "        metadata['file_path'] = str(file_path)\n",
    "        file_metadata_list.append(metadata)\n",
    "    else:\n",
    "        logging.warning(f\"No metadata found in file: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunking the Files\n",
    "Use LangChain's RecursiveCharacterTextSplitter to split the file content into manageable chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8813f28228347288655466af702c83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Chunking files:   0%|          | 0/1041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 5201\n"
     ]
    }
   ],
   "source": [
    "def load_file_content(file_path):\n",
    "    \"\"\"\n",
    "    Loads the content of a Dart file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the Dart file.\n",
    "\n",
    "    Returns:\n",
    "        str: Content of the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading file content from {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Initialize the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # Adjust as needed\n",
    "    chunk_overlap=100,  # Adjust as needed\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# List to hold all chunks with metadata\n",
    "all_chunks = []\n",
    "\n",
    "for metadata in tqdm(file_metadata_list, desc=\"Chunking files\"):\n",
    "    file_path = metadata['file_path']\n",
    "    content = load_file_content(file_path)\n",
    "    \n",
    "    # Remove existing metadata comments to avoid redundancy\n",
    "    comment_style = '//'\n",
    "    content_without_metadata = re.sub(rf'^{comment_style}.*\\n', '', content, flags=re.MULTILINE)\n",
    "    \n",
    "    # Split content into chunks\n",
    "    chunks = text_splitter.split_text(content_without_metadata)\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_metadata = metadata.copy()\n",
    "        chunk_metadata.update({\n",
    "            \"chunk_id\": f\"{Path(file_path).stem}_chunk_{i+1}\",\n",
    "            \"chunk_text\": chunk,\n",
    "            \"file_name\": Path(file_path).name,\n",
    "            \"module_name\": metadata.get(\"Module\", \"Unknown\"),\n",
    "            \"description\": metadata.get(\"Description\", \"\"),\n",
    "            \"dependencies\": metadata.get(\"Dependencies\", \"\"),\n",
    "            \"components\": metadata.get(\"Components\", \"\"),\n",
    "            \"role\": metadata.get(\"Role\", \"\"),\n",
    "            \"author\": metadata.get(\"Author\", \"\"),\n",
    "            \"date_created\": metadata.get(\"Date Created\", \"\"),\n",
    "            \"last_updated\": metadata.get(\"Last Updated\", \"\"),\n",
    "            \"related_files\": metadata.get(\"Related Files\", \"\"),\n",
    "            \"key\": metadata.get(\"Key\", \"\")\n",
    "        })\n",
    "        all_chunks.append(chunk_metadata)\n",
    "\n",
    "print(f\"Total chunks created: {len(all_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ebef2adfd844938a334fe82a51910b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "# Function to generate embedding for a given text\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def get_embedding(text):\n",
    "    try:\n",
    "        return embeddings.embed_query(text)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "# Generate embeddings for all chunks\n",
    "successful_embeddings = 0\n",
    "\n",
    "for chunk in tqdm(all_chunks, desc=\"Generating embeddings\"):\n",
    "    text = chunk['chunk_text']\n",
    "   \n",
    "    embedding = get_embedding(text)\n",
    "    if embedding:\n",
    "        chunk['embedding'] = embedding\n",
    "        successful_embeddings += 1\n",
    "    else:\n",
    "        logging.warning(f\"Failed to generate embedding for chunk: {chunk['chunk_id']}\")\n",
    "\n",
    "print(f\"Successfully generated embeddings for {successful_embeddings} out of {len(all_chunks)} chunks.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents to add: 64\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "for chunk in all_chunks:\n",
    "    if 'embedding' in chunk:\n",
    "        doc = Document(\n",
    "            page_content=chunk['chunk_text'],\n",
    "            metadata={\n",
    "                \"file_path\": chunk['file_path'],\n",
    "                \"file_name\": chunk['file_name'],\n",
    "                \"module_name\": chunk['module_name'],\n",
    "                \"description\": chunk['description'],\n",
    "                \"dependencies\": chunk['dependencies'],\n",
    "                \"components\": chunk['components'],\n",
    "                \"role\": chunk['role'],\n",
    "                \"author\": chunk['author'],\n",
    "                \"date_created\": chunk['date_created'],\n",
    "                \"last_updated\": chunk['last_updated'],\n",
    "                \"related_files\": chunk['related_files'],\n",
    "                \"key\": chunk['key'],\n",
    "                \"chunk_id\": chunk['chunk_id']\n",
    "            }\n",
    "        )\n",
    "        documents.append(doc)\n",
    "\n",
    "print(f\"Total documents to add: {len(documents)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 64 documents to Pinecone.\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'documents' is correctly populated\n",
    "if documents:\n",
    "    vector_store.add_documents(documents)\n",
    "    print(f\"Added {len(documents)} documents to Pinecone.\")\n",
    "else:\n",
    "    print(\"No documents to add to Pinecone.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
