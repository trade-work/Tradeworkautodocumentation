{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.2.10)\n",
      "Requirement already satisfied: langchain-openai in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.1.19)\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.66.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain_community) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain_community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain_community) (0.2.11)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain_community) (0.2.24)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain_community) (0.1.93)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain_community) (8.3.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.32.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-openai) (1.37.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain<0.3.0,>=0.2.9->langchain_community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain<0.3.0,>=0.2.9->langchain_community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain_community) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.7.24)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain_community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_community langchain-openai python-dotenv tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory exists: /Volumes/Mac-External/Development/Tradework/tradework_platform\n",
      "Git repository root: /Volumes/Mac-External/Development/Tradework/tradework_platform\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup\n",
    "import os\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "def get_git_root(repo_directory):\n",
    "    \"\"\"\n",
    "    Determines the root directory of the Git repository.\n",
    "    \n",
    "    Args:\n",
    "        repo_directory (str): Path to any directory within the Git repository.\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the Git repository root, or None if not a Git repository.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['git', '-C', repo_directory, 'rev-parse', '--show-toplevel'],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "        git_root = result.stdout.strip()\n",
    "        return git_root\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"Directory {repo_directory} is not a Git repository.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error determining Git root for {repo_directory}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Set the path to your Flutter/Dart project directory\n",
    "repo_directory = \"/Volumes/Mac-External/Development/Tradework/tradework_platform\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(repo_directory):\n",
    "    print(f\"Directory exists: {repo_directory}\")\n",
    "else:\n",
    "    print(f\"Directory does not exist: {repo_directory}\")\n",
    "\n",
    "# Determine the Git root\n",
    "git_root = get_git_root(repo_directory)\n",
    "if git_root:\n",
    "    print(f\"Git repository root: {git_root}\")\n",
    "else:\n",
    "    print(\"The specified directory is not within a Git repository.\")\n",
    "    exit(1)  # Exit if not a Git repository\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Comment styles based on file type\n",
    "COMMENT_STYLES = {\n",
    "    '.dart': '//',\n",
    "    '.py': '#',\n",
    "    '.yaml': '#',\n",
    "    '.yml': '#',\n",
    "    '.json': '//',     # JSON typically doesn't support comments, but we use // for this purpose\n",
    "    '.html': '<!--',   # HTML uses <!-- -->\n",
    "    '.css': '/*',      # CSS uses /* */\n",
    "    '.js': '//',       # JavaScript uses //\n",
    "    '.ts': '//',       # TypeScript uses //\n",
    "    '.md': '```',      # Markdown for code blocks (if needed)\n",
    "    '.xml': '<!--',    # XML uses <!-- -->\n",
    "    '.cpp': '//',      # C++ style\n",
    "    '.java': '//',     # Java style\n",
    "}\n",
    "\n",
    "def get_comment_style(file_path):\n",
    "    \"\"\"Determine the comment style based on the file extension.\"\"\"\n",
    "    _, ext = os.path.splitext(file_path)\n",
    "    return COMMENT_STYLES.get(ext, '#')  # Default to '#' if extension not found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the template for generating metadata\n",
    "metadata_prompt = \"\"\"\n",
    "You are an AI assistant helping with code documentation for the TradeWork platform. TradeWork is a UK-based property management platform built with Firebase as the backend and Flutter as the Web App frontend. The platform connects landlords, developers, contractors, and subcontractors, supporting project and tender management, vendor selection, and payment processing.\n",
    "\n",
    "The following information is provided to you:\n",
    "- File: {file_name}\n",
    "- Module: {module_name}\n",
    "- Date Created: {date_created}\n",
    "- Last Updated: {last_updated}\n",
    "- Existing Comments: {existing_comments}\n",
    "\n",
    "Based on the file content and the provided information, generate a detailed metadata block. If any field cannot be determined from the file content, infer the best possible answer based on the context of the platform.\n",
    "\n",
    "The format should be:\n",
    "\n",
    "# File: {file_name}\n",
    "# Module: {module_name}\n",
    "# Description: A brief description of what the file does based on its content.\n",
    "# Dependencies: Any dependencies or related files (e.g., Firebase, chat, payment integration, AI chatbot).\n",
    "# Components: The major components or classes defined in the file, such as widgets, BLoCs, models.\n",
    "# Role: Whether the file is role-specific (e.g., Landlord, Developer, Contractor, Subcontractor).\n",
    "# Author: Piers\n",
    "# Date Created: {date_created}\n",
    "# Last Updated: {last_updated}\n",
    "# Related Files: Any related files (BLoC, models, services, etc.).\n",
    "# Key: Keywords like bloc, widget, model, firebase, payment, chat, etc.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the app context with full TradeWork details\n",
    "app_context = \"\"\"\n",
    "TradeWork is a UK-based platform that aggregates resources and professionals within the property market. It allows landlords, developers, and contractors to manage projects, jobs, and tasks. The platform is designed to streamline property-related workflows by providing access to a wide network of skilled professionals and data resources.\n",
    "\n",
    "Key details:\n",
    "- Backend: Firebase (authentication, Firestore, functions for backend logic).\n",
    "- Frontend: Flutter Web App.\n",
    "- Role-based workflows: Landlord, Developer, Contractor, Subcontractor.\n",
    "- Core functionalities: Project creation, tender management, vendor selection, chat, peer ratings, invoice management, payment integration, and AI assistance.\n",
    "\n",
    "Folder structure:\n",
    "1. Core Shared Components (twcore/):\n",
    "   - application/: Manages common logic and state using BLoCs (e.g., authentication, chat).\n",
    "   - models/: Core data models (e.g., user, auth, company) shared across all users.\n",
    "   - services/: Shared services for external integrations, AI, payment, and utilities.\n",
    "   - widgets/: Reusable UI components used throughout the app.\n",
    "\n",
    "2. Shared Features (shared_features/):\n",
    "   - Shared features like AI, project management, and document viewing follow the structure:\n",
    "     - application/: Contains BLoCs managing feature-specific state.\n",
    "     - models/: Feature-specific models.\n",
    "     - ui/: Desktop and mobile-specific UI components.\n",
    "     - services/: Services specific to each feature.\n",
    "     - widgets/: Reusable widgets for feature-related tasks.\n",
    "\n",
    "3. User-Specific Features (users/):\n",
    "   - Each user type (e.g., landlord, contractor, developer) has a similar internal structure:\n",
    "     - Top-Level: Contains user-specific application/, models/, ui/, services/, and widgets/ to handle the overall user interface and core tasks.\n",
    "     - Features: Within each user, specific features (e.g., property management for landlords or bid management for subcontractors) follow the same folder structure:\n",
    "       - application/: BLoCs for managing state related to the feature.\n",
    "       - models/: Feature-specific models.\n",
    "       - ui/: Desktop/mobile-specific UI components for the feature.\n",
    "       - services/: Services for handling feature-specific logic.\n",
    "       - widgets/: Reusable widgets for feature-related tasks.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def has_metadata(file_path, comment_style, required_keys=None):\n",
    "    \"\"\"\n",
    "    Checks if the file already contains the metadata block.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Absolute path to the file.\n",
    "        comment_style (str): The comment prefix based on file type (e.g., '//', '#').\n",
    "        required_keys (list, optional): List of required metadata keys. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if all required metadata keys are found, False otherwise.\n",
    "    \"\"\"\n",
    "    if required_keys is None:\n",
    "        required_keys = [\n",
    "            \"# File:\",\n",
    "            \"# Module:\",\n",
    "            \"# Description:\",\n",
    "            \"# Dependencies:\",\n",
    "            \"# Components:\",\n",
    "            \"# Role:\",\n",
    "            \"# Author:\",\n",
    "            \"# Date Created:\",\n",
    "            \"# Last Updated:\",\n",
    "            \"# Related Files:\",\n",
    "            \"# Key:\"\n",
    "        ]\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            # Read the first N lines where N is the number of required keys\n",
    "            for _ in range(len(required_keys)):\n",
    "                line = file.readline()\n",
    "                if not line:\n",
    "                    break  # Reached EOF\n",
    "                # Remove comment prefix and leading/trailing whitespace\n",
    "                stripped_line = line.strip().lstrip(comment_style).strip()\n",
    "                # Check for each required key\n",
    "                for key in required_keys:\n",
    "                    if stripped_line.startswith(key):\n",
    "                        return True\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error checking metadata in file {file_path}: {e}\")\n",
    "        return False\n",
    "def detect_folder_context(file_path):\n",
    "    if 'twcore' in file_path:\n",
    "        return \"Core Shared Components\"\n",
    "    elif 'shared_features' in file_path:\n",
    "        return \"Shared Features\"\n",
    "    elif 'users' in file_path:\n",
    "        return \"User-Specific Features\"\n",
    "    return \"Unknown\"\n",
    "\n",
    "def get_comment_style(file_path):\n",
    "    COMMENT_STYLES = {\n",
    "        '.dart': '//',\n",
    "        '.py': '#',\n",
    "        '.yaml': '#',\n",
    "        '.yml': '#',\n",
    "        '.json': '//',\n",
    "        '.html': '<!--',\n",
    "        '.css': '/*',\n",
    "        '.js': '//',\n",
    "        '.ts': '//',\n",
    "        '.md': '```',\n",
    "        '.xml': '<!--',\n",
    "        '.cpp': '//',\n",
    "        '.java': '//'\n",
    "    }\n",
    "    _, ext = os.path.splitext(file_path)\n",
    "    return COMMENT_STYLES.get(ext, '#')  # Default to '#' if extension not found\n",
    "\n",
    "def extract_imports(file_content):\n",
    "    \"\"\"Extracts import statements from a Dart file.\"\"\"\n",
    "    import_lines = []\n",
    "    for line in file_content.splitlines():\n",
    "        if line.strip().startswith('import'):\n",
    "            import_lines.append(line)\n",
    "    return import_lines\n",
    "\n",
    "def extract_top_comments(file_content, comment_style):\n",
    "    \"\"\"Extract the top comments from the file.\"\"\"\n",
    "    comment_lines = []\n",
    "    for line in file_content.splitlines():\n",
    "        line = line.strip()\n",
    "        if line.startswith(comment_style):\n",
    "            comment_lines.append(line)\n",
    "        else:\n",
    "            break  # Stop when we hit the first non-comment line\n",
    "    return \"\\n\".join(comment_lines), \"\\n\".join(file_content.splitlines()[len(comment_lines):])  # Return the comments and the rest of the code\n",
    "\n",
    "\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def get_git_creation_date(file_path, git_root):\n",
    "    \"\"\"\n",
    "    Retrieves the creation date of a file based on Git history.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Absolute path to the file.\n",
    "        git_root (str): Absolute path to the Git repository root.\n",
    "    \n",
    "    Returns:\n",
    "        str: Creation date in 'YYYY-MM-DD' format, or None if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert absolute file path to relative path from git_root\n",
    "        relative_path = os.path.relpath(file_path, git_root)\n",
    "        \n",
    "        # Ensure the file is tracked by git\n",
    "        subprocess.run(\n",
    "            ['git', '-C', git_root, 'ls-files', '--error-unmatch', relative_path],\n",
    "            check=True,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE\n",
    "        )\n",
    "        \n",
    "        # Get the first commit where the file was added\n",
    "        result = subprocess.run(\n",
    "            ['git', '-C', git_root, 'log', '--diff-filter=A', '--follow', '--format=%aI', '--', relative_path],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "        creation_date_str = result.stdout.strip().split('\\n')[0]\n",
    "        if creation_date_str:\n",
    "            creation_date = datetime.fromisoformat(creation_date_str).strftime('%Y-%m-%d')\n",
    "            return creation_date\n",
    "        else:\n",
    "            print(f\"No creation date found in Git history for {relative_path}.\")\n",
    "            return None\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"File {file_path} is not tracked by Git.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting Git creation date for {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_file_metadata(file_path, git_root):\n",
    "    \"\"\"\n",
    "    Retrieves the creation and last updated dates of a file.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Absolute path to the file.\n",
    "        git_root (str): Absolute path to the Git repository root.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (date_created, last_updated) in 'YYYY-MM-DD' format.\n",
    "    \"\"\"\n",
    "    date_created = get_git_creation_date(file_path, git_root)\n",
    "    if not date_created:\n",
    "        # Fallback to st_ctime if Git fails\n",
    "        try:\n",
    "            file_stats = os.stat(file_path)\n",
    "            date_created = datetime.fromtimestamp(file_stats.st_ctime).strftime('%Y-%m-%d')\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting st_ctime for {file_path}: {e}\")\n",
    "            date_created = \"Unknown\"\n",
    "    \n",
    "    try:\n",
    "        last_updated = datetime.fromtimestamp(os.stat(file_path).st_mtime).strftime('%Y-%m-%d')\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting st_mtime for {file_path}: {e}\")\n",
    "        last_updated = \"Unknown\"\n",
    "    \n",
    "    return date_created, last_updated\n",
    "\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='file_processing.log',\n",
    "    filemode='a',\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_import_path(import_statement, current_file_path, lib_directory):\n",
    "    \"\"\"Extracts the file path from a Dart import statement.\n",
    "\n",
    "    Handles relative paths and package paths for local files.\n",
    "    \"\"\"\n",
    "    # Match import statements like: import 'some_relative_path.dart';\n",
    "    match = re.search(r\"import\\s+['\\\"]([^'\\\"]+)['\\\"];\", import_statement)\n",
    "    \n",
    "    if match:\n",
    "        import_path = match.group(1)\n",
    "        \n",
    "        # Handle relative paths\n",
    "        if import_path.startswith('.'):\n",
    "            # Convert relative paths to absolute paths based on the current file's location\n",
    "            base_dir = os.path.dirname(current_file_path)\n",
    "            absolute_path = os.path.abspath(os.path.join(base_dir, import_path))\n",
    "            # Ensure the path points to a Dart file\n",
    "            if not absolute_path.endswith('.dart'):\n",
    "                absolute_path += '.dart'\n",
    "            if os.path.exists(absolute_path):\n",
    "                return absolute_path\n",
    "        \n",
    "        # Handle package paths\n",
    "        elif import_path.startswith('package:tradework_platform/'):\n",
    "            # Remove 'package:tradework_platform/' and map to lib_directory\n",
    "            relative_path = import_path.replace('package:tradework_platform/', '')\n",
    "            absolute_path = os.path.join(lib_directory, relative_path)\n",
    "            if os.path.exists(absolute_path):\n",
    "                return absolute_path\n",
    "        \n",
    "        # Handle other package paths if needed\n",
    "        elif import_path.startswith('package:'):\n",
    "            # You can add custom logic to map other package imports to actual file paths in your repo if needed\n",
    "            return None\n",
    "        \n",
    "    return None  # If not a valid import line or if a package import (ignored for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def process_file(file_path, memory, core_files, processed_files, chain, app_context, lib_directory, git_root, only_missing=False):\n",
    "    \"\"\"\n",
    "    Processes a single Dart file:\n",
    "    - Skips auto-generated files.\n",
    "    - Optionally skips files that already contain metadata.\n",
    "    - Extracts and removes existing top comments.\n",
    "    - Generates new metadata using LLM.\n",
    "    - Inserts the new metadata at the top of the file.\n",
    "    - Recursively processes imported files.\n",
    "    \"\"\"\n",
    "    # Skip files that end with .freezed.dart or .g.dart or already processed\n",
    "    if file_path.endswith('.freezed.dart') or file_path.endswith('.g.dart') or file_path in processed_files:\n",
    "        logging.info(f\"Skipping file: {file_path}\")\n",
    "        return\n",
    "\n",
    "    logging.info(f\"Processing file: {file_path}\")\n",
    "\n",
    "    # Determine the comment style based on file extension\n",
    "    comment_style = get_comment_style(file_path)\n",
    "\n",
    "    # If only_missing flag is set, check for existing metadata\n",
    "    if only_missing:\n",
    "        if has_metadata(file_path, comment_style):\n",
    "            logging.info(f\"Metadata already exists. Skipping file: {file_path}\")\n",
    "            return\n",
    "\n",
    "    try:\n",
    "        # Read the file content\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            code_content = file.read()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading file {file_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Get file metadata (creation and last updated dates)\n",
    "    date_created, last_updated = get_file_metadata(file_path, git_root)\n",
    "\n",
    "    # Get folder context to add to the metadata\n",
    "    folder_context = detect_folder_context(file_path)\n",
    "\n",
    "    # Extract the filename\n",
    "    file_name = os.path.basename(file_path)\n",
    "\n",
    "    # Extract existing comments from the top of the file\n",
    "    existing_comments, code_content_without_comments = extract_top_comments(code_content, comment_style)\n",
    "\n",
    "    # Prepare context by including core files content\n",
    "    context_files_content = \"\"\n",
    "    for core_file in core_files:\n",
    "        if os.path.exists(core_file):\n",
    "            try:\n",
    "                with open(core_file, 'r', encoding='utf-8') as cf:\n",
    "                    context_files_content += cf.read() + \"\\n\"\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error reading core file {core_file}: {e}\")\n",
    "\n",
    "    # Use the LLM to generate the metadata\n",
    "    try:\n",
    "        result = chain.invoke({\n",
    "            \"code_content\": code_content_without_comments,\n",
    "            \"app_context\": app_context + \"\\n\" + context_files_content,\n",
    "            \"last_updated\": last_updated,\n",
    "            \"date_created\": date_created,\n",
    "            \"file_name\": file_name,\n",
    "            \"module_name\": folder_context,\n",
    "            \"existing_comments\": existing_comments\n",
    "        })\n",
    "        generated_metadata = result.get('text', '').strip()\n",
    "        logging.debug(f\"LLM Output for {file_path}:\\n{generated_metadata}\\n\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error invoking LLM for file {file_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Verify that all required keys are present\n",
    "    required_keys = [\n",
    "        \"# File:\",\n",
    "        \"# Module:\",\n",
    "        \"# Description:\",\n",
    "        \"# Dependencies:\",\n",
    "        \"# Components:\",\n",
    "        \"# Role:\",\n",
    "        \"# Author:\",\n",
    "        \"# Date Created:\",\n",
    "        \"# Last Updated:\",\n",
    "        \"# Related Files:\",\n",
    "        \"# Key:\"\n",
    "    ]\n",
    "\n",
    "    missing_keys = [key for key in required_keys if key not in generated_metadata]\n",
    "    if missing_keys:\n",
    "        logging.warning(f\"Missing metadata keys in {file_path}: {missing_keys}\")\n",
    "\n",
    "    # Add comment style to each line of the metadata\n",
    "    metadata_comment = \"\\n\".join([f\"{comment_style} {line}\" for line in generated_metadata.splitlines()])\n",
    "\n",
    "    # Insert generated metadata at the start of the file\n",
    "    try:\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(metadata_comment + \"\\n\" + code_content_without_comments)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error writing metadata to file {file_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Add the file to the processed list\n",
    "    processed_files.add(file_path)\n",
    "\n",
    "    # Extract imports and process dependencies\n",
    "    import_lines = extract_imports(code_content_without_comments)\n",
    "    for import_line in import_lines:\n",
    "        # Extract the path from the import and process the imported file\n",
    "        import_path = extract_import_path(import_line, file_path, lib_directory)\n",
    "        if import_path and import_path not in processed_files:\n",
    "            process_file(import_path, memory, core_files, processed_files, chain, app_context, lib_directory, git_root, only_missing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def process_repository(directory, memory, chain, app_context, git_root, only_missing=False, chunk_size=20):\n",
    "    \"\"\"\n",
    "    Processes all Dart files in the specified directory.\n",
    "    - Prioritizes core files (e.g., main.dart, locator.dart, routes.dart).\n",
    "    - Tracks processed files to avoid duplication.\n",
    "    - Uses a progress bar to display processing status.\n",
    "    \"\"\"\n",
    "    lib_directory = directory  # Assuming 'directory' is the 'lib' folder\n",
    "\n",
    "    # Prioritize certain core files (like main.dart and services)\n",
    "    core_files = []\n",
    "    main_file = os.path.join(lib_directory, \"main.dart\")\n",
    "    if os.path.exists(main_file):\n",
    "        core_files.append(main_file)\n",
    "\n",
    "    # Add other core files manually (like service locator, route)\n",
    "    core_files.extend([\n",
    "        os.path.join(lib_directory, \"services\", \"locator.dart\"),\n",
    "        os.path.join(lib_directory, \"routes\", \"routes.dart\")\n",
    "    ])\n",
    "\n",
    "    # Initialize set to track processed files\n",
    "    processed_files = set()\n",
    "\n",
    "    # First, process core files\n",
    "    for core_file in core_files:\n",
    "        if os.path.exists(core_file) and core_file not in processed_files:\n",
    "            process_file(core_file, memory, core_files, processed_files, chain, app_context, lib_directory, git_root, only_missing)\n",
    "\n",
    "    # Collect all other Dart files excluding auto-generated ones\n",
    "    all_files = sorted([\n",
    "        os.path.join(root, file_name) for root, dirs, files in os.walk(lib_directory)\n",
    "        for file_name in files\n",
    "        if file_name.endswith(\".dart\") and not file_name.endswith(('.freezed.dart', '.g.dart'))\n",
    "    ], key=lambda x: x.lower())\n",
    "\n",
    "    # Calculate the number of files to process (excluding already processed)\n",
    "    files_to_process = [f for f in all_files if f not in processed_files]\n",
    "    total_files = len(files_to_process)\n",
    "    print(f\"Total files to process: {total_files}\\n\")\n",
    "\n",
    "    # Use tqdm to display a progress bar\n",
    "    with tqdm(total=total_files, desc=\"Processing files\", unit=\"file\") as pbar:\n",
    "        for file_path in files_to_process:\n",
    "            process_file(file_path, memory, core_files, processed_files, chain, app_context, lib_directory, git_root, only_missing)\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(\"\\nProcessing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the LLM using GPT-4o-mini (or another GPT model of your choice)\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "\n",
    "# Create a LangChain prompt template for file processing\n",
    "prompt = PromptTemplate(\n",
    "        input_variables=[\"code_content\", \"app_context\", \"last_updated\", \"date_created\", \"file_name\", \"module_name\", \"existing_comments\"],\n",
    "        template=metadata_prompt\n",
    "    )\n",
    "# Define a chain to process files with the given LLM and prompt template\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "    \n",
    "# Initialize memory for tracking context and window resets\n",
    "memory = ConversationBufferWindowMemory(k=5)  # Keep 5 file contexts in memory at a time\n",
    "\n",
    "# Define the repository's lib directory\n",
    "lib_directory = os.path.join(repo_directory, \"lib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_missing = True  # Set to False to process all files\n",
    "\n",
    "\n",
    "\n",
    "# Run the processing starting from main.dart\n",
    "# repo_directory = \"path_to_your_flutter_repo\"\n",
    "process_repository(lib_directory, memory, chain, app_context, git_root, only_missing=only_missing)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
